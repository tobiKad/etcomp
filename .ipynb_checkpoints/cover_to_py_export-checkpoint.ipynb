{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-b2799eb1f761>, line 175)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-b2799eb1f761>\"\u001b[0;36m, line \u001b[0;32m175\u001b[0m\n\u001b[0;31m    df_interpolated.to_csv('./data/all_data_interpolated/p' + str(counter) + '_interpolated.csv', index = False)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load all ASC = Eyelink Raw data using build in library edfreader\n",
    "sys.path.append('./data_preprocessing/data_conversion/PyGazeAnalyser-master/pygazeanalyser')\n",
    "from edfreader import read_edf\n",
    "print('loaded EDF reader')\n",
    "\n",
    "## Internal libraries\n",
    "from data_preprocessing import interpolationET\n",
    "from data_preprocessing import cross_correlation\n",
    "from data_preprocessing import fixation_plots\n",
    "\n",
    "# Loading data files from the directory\n",
    "for files in sorted(glob.glob(\"./ascData/p*.asc\"),key=os.path.getmtime):\n",
    "\n",
    "    print('loading subject file - ' + str(files))\n",
    "\n",
    "counter = 0\n",
    "modification_calc=True\n",
    "for files in sorted(glob.glob(\"./ascData/p*.asc\"),key=os.path.getmtime):\n",
    "    counter = counter +1\n",
    "    # Extract Raw Data\n",
    "    data = files\n",
    "    \n",
    "    data_raw = read_edf(data, 'START', debug=False)\n",
    "    type(data_raw), len(data_raw), type(data_raw[0]), data_raw[0].keys()\n",
    "    \n",
    "    #     Open Asci data and create a list 'lines' with each row line from the ASC data\n",
    "    asci_data = open(data, 'r')\n",
    "    lines = []\n",
    "    for line in asci_data:\n",
    "        lines.append(line)\n",
    "    # Iterate for each row\n",
    "    for idx, line in enumerate(lines):\n",
    "        if 'poczatek' in line:\n",
    "            time_line = lines[idx].split()      \n",
    "            break\n",
    "\n",
    "    # Retrieve machine EYelink time in ms\n",
    "    eyelink_time_start = int(time_line[1])\n",
    "    print(\"Eyelink machine start time in ms \" + str(eyelink_time_start))\n",
    "    \n",
    "    # Splitting text and number in string \n",
    "    display_split_unix = [re.findall(r'[\\d\\.\\d]+', time_line[-1])[0] ]\n",
    "    tracker_start = [re.findall(r'[\\d\\.\\d]+', time_line[1])[0] ]\n",
    "    tracker_start = int(float(tracker_start[0]))\n",
    "    # # #Converting to miliseconds\n",
    "    display_time_ml_start = int(float(display_split_unix[0]) * 1000)\n",
    "    print(\"Eyelink machine start time in UNIX ms \" + str(display_time_ml_start))\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "    \n",
    "    # Same for the END koniec means end\n",
    "    for idx, line in enumerate(lines):\n",
    "        if 'koniec' in line:\n",
    "            time_line = lines[idx].split()\n",
    "            break\n",
    "\n",
    "    eyelink_time_end = int(time_line[1])\n",
    "\n",
    "    display_split = time_line[-1]\n",
    "\n",
    "    # # Using re.findall()\n",
    "    # # Splitting text and number in string \n",
    "    display_split = [re.findall(r'[\\d\\.\\d]+', time_line[-1])[0] ]\n",
    "\n",
    "    tracker_end = [re.findall(r'[\\d\\.\\d]+', time_line[1])[0] ]\n",
    "    tracker_end = int(float(tracker_end[0])) - 1\n",
    "\n",
    "    # #Converting to miliseconds\n",
    "    display_time_ml_end = int(float(display_split[0]) * 1000)\n",
    "    print(\"End time for Eyelink in UNIX timestamp ms \" + str(display_time_ml_end))\n",
    "    \n",
    "    # Create columns for the data\n",
    "    df_all = pd.DataFrame(columns = ['X', 'Y', 'Tracker_Time','Display_Time','Time'])\n",
    "    # Create empty dataframe for Eyelink data\n",
    "    x = []\n",
    "    y = []\n",
    "    time = []\n",
    "    for i in range(len(data_raw)):\n",
    "        x = x + list(data_raw[i]['x'])\n",
    "        y = y + list(data_raw[i]['y'])\n",
    "        time = time + list(data_raw[i]['trackertime'])\n",
    "\n",
    "    #Checking if there are nan values\n",
    "\n",
    "    df_all.X = x\n",
    "    df_all.Y = y\n",
    "    df_all.Tracker_Time = time\n",
    "    df_all.Display_Time = np.nan\n",
    "    \n",
    "    # Compute the time for Eyelink substracting the last and first trigger time in ms from Unix timestamp\n",
    "    diff_between_end = tracker_end - display_time_ml_end\n",
    "    diff_between_start = tracker_start - display_time_ml_start\n",
    "    \n",
    "    # Then take this difference and subtract from all trackers time, then you would adjust the timestamp to \n",
    "    # the LAST reliable trigger\n",
    "    df_all['Time'] = df_all['Tracker_Time'] - diff_between_end\n",
    "    tracker_end = df_all.Time.tail(1).values[0]\n",
    "    \n",
    "    # Drop not used columns\n",
    "    df_all = df_all.drop(columns=['Display_Time'])\n",
    "    \n",
    "    ## LOAD, FORMAT AND RESAMPLE up to 300hz LABVANCED DATA\n",
    "    lb = pd.read_csv('./data/lb_data/timeseries_data/p2' + '_XYTC.csv')\n",
    "    # Format to change the column name and remove between trials empty columns\n",
    "    lb = interpolationET.formating_labvanced(lb)\n",
    "    lb = lb.sort_values(by=['time_lb'])\n",
    "    #     Resample Data\n",
    "    lb.isna().sum()\n",
    "    \n",
    "    lb_resampled = cross_correlation.resampleData(lb)\n",
    "    lb_resampled.isna().sum()\n",
    "    lb_resampled = lb_resampled[lb_resampled['timestamp'].notna()]\n",
    "    \n",
    "    # FORMAT AND RESAMPLE up to 300hz EYELINK\n",
    "    el = interpolationET.formating_eyelink(df_all)\n",
    "    el_resampled = cross_correlation.resampleDataEyelink(el)\n",
    "    \n",
    "    # Interpolate data to have equal size of the index and preparing it for the crosslag correlation:\n",
    "    df_interpolated = interpolationET.interpolation (el_resampled, lb_resampled)\n",
    "    # # Reset index to take off the timestamp column\n",
    "    df_interpolated = df_interpolated.reset_index()\n",
    "    \n",
    "    # Calculating delay between two eyetrackers\n",
    "    delay = cross_correlation.createLagSygCorrelation(df_interpolated)\n",
    "    # Convert lag to ms\n",
    "    ms_delay = delay*2\n",
    "    print(\"Delay between Labvanced 300hz and Eyelink 300hz resampled = \" + str(ms_delay))\n",
    "    # Take the first Labvanced Timestamp this is the trigger which we did fix\n",
    "    display_time_ml_start_first_task = df_interpolated.time_lb.head(1).values[0]\n",
    "    # Fix the tracker start based on the Labvanced trigger + miliseconds_delay(lag)\n",
    "    new_tracker_start = abs(display_time_ml_start_first_task + ms_delay)\n",
    "\n",
    "    #  now for the linear model that interpolates all times, you use:\n",
    "    # linear interpolation\n",
    "    a = (display_time_ml_end - display_time_ml_start_first_task)/(tracker_end-new_tracker_start)\n",
    "    b = - new_tracker_start * a + display_time_ml_start_first_task\n",
    "\n",
    "    # Fix the time column\n",
    "    df_all['Time'] = abs(df_all['Time'] * a + b)\n",
    "    \n",
    "    # Here we RE-NAME the column Time which we just correct with time_el, which is valid for other functions.\n",
    "    el_crossCorrelated = interpolationET.formating_eyelink(df_all)\n",
    "    \n",
    "    ## Now we load data once again because we only wanted to resample data for the cross correlation,\n",
    "    # Now we want to interpolate with data with the Labvanced 30Hz frame rate.\n",
    "    lb_30hz = pd.read_csv('./data/lb_data/timeseries_data/p' + str(counter) + '_XYTC.csv')\n",
    "\n",
    "    lb_30hz = interpolationET.formating_labvanced(lb_30hz)\n",
    "    lb_30hz = lb_30hz.set_index('time_lb')\n",
    "    lb_30hz = lb_30hz.sort_index(ascending=True)\n",
    "    \n",
    "    # Interpolating Eyelink after lag sync and with Labvanced data to create one dataframe.\n",
    "    df_interpolated = interpolationET.interpolation (el_crossCorrelated, lb_30hz)\n",
    "    df_interpolated = df_interpolated.reset_index()\n",
    "    \n",
    "    df_large_grid = df_interpolated[df_interpolated['Task_Name'] == 'large_grid']\n",
    "    df_large_grid.reset_index(inplace=True)\n",
    "    \n",
    "    df_interpolated.sort_index(ascending=True)\n",
    "    df_interpolated.reset_index(inplace=True)\n",
    "    \n",
    "    delay = cross_correlation.createLagSygCorrelation(df_interpolated)\n",
    "    ms_delay = delay*2\n",
    "    print(\"Lag after cross correlation and inteporlation is = \" + str(ms_delay)\n",
    "          \n",
    "    fixation_plots.timeSeriesSyncPlot(df_interpolated.loc[0:100].time_lb, df_interpolated.loc[0:100].Y_lb, df_interpolated.loc[0:100].Y_el)\n",
    "    fixation_plots.timeSeriesSyncPlot(df_interpolated.loc[100:400].time_lb, df_interpolated.loc[100:400].Y_lb, df_interpolated.loc[100:400].Y_el)\n",
    "    fixation_plots.timeSeriesSyncPlot(df_interpolated.loc[-1:300].time_lb, df_interpolated.loc[-1:300].Y_lb, df_interpolated.loc[-1:300].Y_el)\n",
    "    fixation_plots.timeSeriesSyncPlot(df_interpolated.time_lb, df_interpolated.Y_lb, df_interpolated.Y_el)\n",
    "          \n",
    "    fixation_plots.timeSeriesSyncPlot(df_large_grid.loc[0:100].time_lb, df_large_grid.loc[0:100].Y_lb, df_large_grid.loc[0:100].Y_el)\n",
    "    fixation_plots.timeSeriesSyncPlot(df_large_grid.loc[100:400].time_lb, df_large_grid.loc[100:400].Y_lb, df_large_grid.loc[100:400].Y_el)\n",
    "    fixation_plots.timeSeriesSyncPlot(df_large_grid.loc[-1:300].time_lb, df_large_grid.loc[-1:300].Y_lb, df_large_grid.loc[-1:300].Y_el)\n",
    "    fixation_plots.timeSeriesSyncPlot(df_large_grid.time_lb, df_large_grid.Y_lb, df_large_grid.Y_el)\n",
    "          \n",
    "    df_interpolated.to_csv('./data/all_data_interpolated/p' + str(counter) + '_interpolated.csv', index = False)\n",
    "          \n",
    "    ## Fixations Extraction Code\n",
    "\n",
    "    print('creating fixation events')\n",
    "    # Create data frame for events\n",
    "    df = pd.DataFrame(columns = ['x', 'y', 'Start', 'End'])\n",
    "    # Parse event to have the beginning and end time\n",
    "    for i in range(len(data_raw)):\n",
    "        trial = i+1\n",
    "        for j in range(len(data_raw[i]['events']['Efix'])):\n",
    "            row = { 'x':0, 'y':0, 'Start':0, 'End':0}\n",
    "\n",
    "            x = data_raw[i]['events']['Efix'][j][3]\n",
    "            y = data_raw[i]['events']['Efix'][j][4]\n",
    "            start = data_raw[i]['events']['Efix'][j][0]\n",
    "            end = data_raw[i]['events']['Efix'][j][1]\n",
    "\n",
    "            row['x'] = x\n",
    "            row['y'] = y\n",
    "            row['Start'] = start\n",
    "            row['End'] = end\n",
    "\n",
    "            df = df.append(row, ignore_index=True)\n",
    "\n",
    "    # Convert Start and End time using end trigger to unix timestamp\n",
    "    df['Start'] = abs((df.Start - diff_between_end))\n",
    "    df['End'] = abs((df.End - diff_between_end) )\n",
    "    # Interpolate the fixations from starting and ending trigger\n",
    "    df['Start'] = df['Start'] * a + b\n",
    "    df['End'] = df['End'] * a + b\n",
    "    df.Start = df.Start.apply(lambda x: '%.0f' % x)\n",
    "    df.End = df.End.apply(lambda x: '%.0f' % x)\n",
    "    df.to_csv('./data/el_data/el_events/p' + str(counter) + '_events.csv', index = False)\n",
    "    print('fixation data saved, for participant =' + str(counter))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
